{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Satellite images of the farmers location from multiple timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from python_scripts.connector import *\n",
    "from python_scripts.helper import *\n",
    "\n",
    "from eval_scripts.evalscript_true_color import *\n",
    "from eval_scripts.evalscript_ndvi import *\n",
    "from eval_scripts.evalscript_ndvi_values  import *\n",
    "\n",
    "from sentinelhub import MimeType, CRS, BBox, SentinelHubRequest, SentinelHubDownloadClient,DataCollection, bbox_to_dimensions, SHConfig\n",
    "from sentinelhub.geo_utils import to_wgs84\n",
    "from sentinelhub.constants import CRS\n",
    "from sentinelhub import SentinelHubCatalog\n",
    "\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Get the necessary timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_slots(start, end, chunks):\n",
    "    \"\"\"\n",
    "    Get the avalable time windows (time slots)\n",
    "    \"\"\" \n",
    "    datetime_start = datetime.datetime.strptime(start, '%Y-%m-%d')\n",
    "    datetime_end   = datetime.datetime.strptime(end, '%Y-%m-%d')\n",
    "    \n",
    "    tdelta = (datetime_end - datetime_start) / chunks\n",
    "    edges = [(datetime_start + i*tdelta).date().isoformat() for i in range(chunks)]\n",
    "    slots = [(edges[i], edges[i+1]) for i in range(len(edges)-1)]\n",
    "    return slots\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slots = get_time_slots('2017-01-01', '2022-01-01', 5)\n",
    "print(\"Yearly time windows\")\n",
    "for slot in slots:\n",
    "    print(slot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Get the necessary coordinates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert coordinations_file (csv file) into a dataframe\n",
    "coordinations_df = pd.read_excel('data/locations/FarmerLocationExtract4Interns_sentinel-hub.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on how far wail is with the conversion of the coordinates of the farmers location, we need to check whether or \n",
    "# the coordination needs to mdofied. \n",
    "coordinations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinations_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_converter(x):\n",
    "    \"\"\"\n",
    "    Convert coordinates (longitude, latitude) in to a bbox in WGS84 format.\n",
    "    \n",
    "    return [long, lat, long, lat]\n",
    "    \"\"\"\n",
    "    lng, lat = to_wgs84(x['P1_Longitude'], x['P1_Latitude'], CRS.WGS84)\n",
    "    coords = [lng -  0.025, lat - 0.025, lng +  0.022, lat + 0.022]\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocations  = coordinations_df[['P1_Longitude', 'P1_Latitude']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocations[geolocations['P1_Latitude'].str.contains('\"')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocations['P1_Latitude'] = geolocations['P1_Latitude'].str.replace('\"', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocations[geolocations['P1_Latitude'].str.contains('\"')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocations = geolocations.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocations.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocations.iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geolocations.to_csv('coordinaten.csv', sep='\\t')\n",
    "geolocations.iloc[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download all the satellite images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time # time the performance\n",
    "import os, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_clouds():\n",
    "    return { \n",
    "    \"dataFilter\": { \n",
    "        \"maxCloudCoverage\": 0\n",
    "        } \n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_folder(folder):\n",
    "    \"\"\"\n",
    "    delete files in folder \n",
    "    \"\"\"\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_folder('../data/images')\n",
    "empty_folder('../data/ndvi_values_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_request_(evalscript, time_interval, coords, data_folder):\n",
    "    return SentinelHubRequest(\n",
    "        data_folder=data_folder, \n",
    "        evalscript=evalscript, \n",
    "        input_data=[\n",
    "        SentinelHubRequest.input_data(\n",
    "            data_collection=DataCollection.SENTINEL2_L2A, \n",
    "            time_interval=time_interval,\n",
    "            other_args = least_clouds())], \n",
    "        bbox=BBox(coords,crs=CRS.WGS84), \n",
    "        config=config, \n",
    "        size=[512, 512], \n",
    "        responses=[SentinelHubRequest.output_response('default', MimeType.PNG)])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_scripts.evalscript_true_color import *\n",
    "from eval_scripts.evalscript_forest import *\n",
    "from eval_scripts.evalscript_ndvi import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(geolocations, evalscript, slots, data_folder):\n",
    "    for index, row in geolocations.iterrows(): # iterate through each location\n",
    "        # create a list of requests\n",
    "        coords = bbox_converter(row) # convert each location to a bbox\n",
    "        print(coords)\n",
    "\n",
    "        list_of_requests = [get_request_(evalscript,slot, coords,data_folder) for slot in slots]\n",
    "        list_of_requests = [request.download_list[0] for request in list_of_requests]\n",
    "        \n",
    "        # download data with multiple threads\n",
    "        SentinelHubDownloadClient(config=config).download(list_of_requests, max_threads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "download_images(geolocations.iloc[:3],evalscript_true_color, slots, '../data/images_completed_png' )\n",
    "end = time.perf_counter()\n",
    "print(\"Done in: {} seconds\".format( end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dowload mask - duurt heel lang\n",
    "start = time.perf_counter()\n",
    "download_images(geolocations.iloc[:10],evalscript_ndvi, slots, '../data/mask_completed' )\n",
    "end = time.perf_counter()\n",
    "print(\"Done in: {} seconds\".format( end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mask_v2(geolocations, slots, data_folder):\n",
    "    for index, rows in geolocations.iterrows(): \n",
    "        coords = bbox_converter(rows) # convert each location to a bbox\n",
    "        for slot in slots:\n",
    "            img_ndvi = sentinel_request(evalscript_ndvi_values, coords, slot, config, False, data_folder, other_args=least_clouds())\n",
    "            min_ndvi = 0.6\n",
    "            ndvi_copy = img_ndvi.copy()\n",
    "            labels = np.where(ndvi_copy > min_ndvi, 255, 0)\n",
    "            labels = labels.astype(np.uint8)\n",
    "            img = Image.fromarray(labels)\n",
    "            filename = \"{}_{}_{}_{}_{}_{}\".format(coords[0], coords[1], coords[2],coords[3], slot[0], slot[1])\n",
    "            img.save(f'{data_folder}/{filename}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "download_mask_v2(geolocations.iloc[:30], slots,'../data/ndvi_values_mask')\n",
    "end = time.perf_counter()\n",
    "print(\"Done in: {} seconds\".format( end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and rename images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(path):\n",
    "    input_json = open(path)\n",
    "    pased_json = json.load(input_json)\n",
    "    return pased_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_filename(json):\n",
    "\n",
    "    item =  json['payload']['input']\n",
    "    bbox = item['bounds']['bbox']\n",
    "    date_start= item['data'][0]['dataFilter']['timeRange']['from'].split(\"T\")[0]\n",
    "    date_end  = item['data'][0]['dataFilter']['timeRange']['to'].split(\"T\")[0]\n",
    "    \n",
    "    return \"{}_{}_{}_{}_{}_{}\".format(bbox[0], bbox[1], bbox[2],bbox[3], date_start, date_end) # TODO : check format and . in naamgeving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build_filename(parse_json(r'C:\\Users\\Amaryllis Lee\\FARM-deforestation\\data\\images\\1484b4269e568648b673959b5a955ce4\\request.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_structure(rootdir,new_rootdir):\n",
    "    for root, subdirectories, files in os.walk(rootdir):\n",
    "        for subdirectory in subdirectories: # for each folder in dir:\n",
    "            request_json = f'{rootdir}/{subdirectory}/request.json'\n",
    "            response_png = f'{rootdir}/{subdirectory}/response.png'\n",
    "            if os.path.isfile(request_json) and os.path.isfile(response_png):\n",
    "                json_file = parse_json(request_json)\n",
    "                new_filename = f'{new_rootdir}/{build_filename(json_file)}.png'\n",
    "                shutil.copyfile(response_png,new_filename)\n",
    "            # get image:\n",
    "            #rename image\n",
    "            #move to data amsk aand remove folder/subdir\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_folder('../data/images_completed_png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir_true_colors = '../data/images_completed_png'\n",
    "new_rootdir_true_colors = '../data/images_completed_png'\n",
    "images_structure(rootdir_true_colors, new_rootdir_true_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying filename move mask to mask_png_testset\n",
    "# rootdir_mask = '../data/mask'\n",
    "# new_rootdir_mask= '../data/mask_png_testset'\n",
    "# images_structure(rootdir, new_rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
